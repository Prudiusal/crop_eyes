{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPmIwMgFxY4k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcO5ivx_uXkc",
        "outputId": "37e45e82-fdb8-460d-b9c2-a3ac3559f119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9ITA9LZvpof",
        "outputId": "38616602-1416-4ef5-e4b7-ba1d5d26f352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, mtcnn\n",
            "Successfully installed lz4-4.3.3 mtcnn-1.0.0\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "--2024-10-08 12:37:22--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  18.7MB/s    in 3.3s    \n",
            "\n",
            "2024-10-08 12:37:26 (18.7 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install mtcnn\n",
        "!pip install dlib\n",
        "!pip install opencv-python\n",
        "!pip install opencv-contrib-python\n",
        "\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vItXnD3ueck",
        "outputId": "c4442630-20da-4fea-fdf0-113e2a1e0719"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "video_path = Path('/content/drive/MyDrive/Personal/BUDKA/Copy of 07.mp4')\n",
        "video_path = Path('/content/drive/MyDrive/Personal/BUDKA/cropped_short.mp4')\n",
        "video_path.exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAU9bGsCvtLa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89YBX6LbvypH"
      },
      "outputs": [],
      "source": [
        "# Initialize MTCNN for face detection and Dlib for facial landmark detection\n",
        "detector = MTCNN(device='GPU:0')  # Face detector\n",
        "landmark_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')  # Download the file if needed\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(video_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Shci9mcRwVhW"
      },
      "outputs": [],
      "source": [
        "def extract_landmarks(frame, faces):\n",
        "    # Convert to grayscale for dlib\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # List to store landmark positions for each face\n",
        "    landmarks_list = []\n",
        "\n",
        "    for face in faces:\n",
        "        x, y, w, h = face['box']\n",
        "        rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))\n",
        "\n",
        "        # Get the landmarks for the face\n",
        "        landmarks = landmark_predictor(gray, rect)\n",
        "\n",
        "        # Extract the (x, y) coordinates of the eyes, brows, and nose\n",
        "        coords = np.zeros((68, 2), dtype=\"int\")\n",
        "        for i in range(0, 68):\n",
        "            coords[i] = (landmarks.part(i).x, landmarks.part(i).y)\n",
        "\n",
        "        landmarks_list.append(coords)\n",
        "\n",
        "    return landmarks_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8KjnjknwraF"
      },
      "outputs": [],
      "source": [
        "# def crop_eye_nose_brow(frame, landmarks):\n",
        "def crop_eye_brow(frame, landmarks):\n",
        "    # Points for the left eye, right eye, brows, and nose bridge\n",
        "    eye_brow_points = landmarks[17:27]  # Brows\n",
        "    eye_points = landmarks[36:48]       # Eyes\n",
        "    # nose_bridge = landmarks[27:31]      # Nose bridge\n",
        "\n",
        "    # Combine the points and create a bounding box\n",
        "    # all_points = np.concatenate((eye_brow_points, eye_points, nose_bridge))\n",
        "    all_points = np.concatenate((eye_brow_points, eye_points))\n",
        "\n",
        "    x, y, w, h = cv2.boundingRect(all_points)\n",
        "\n",
        "    # Add some padding around the region\n",
        "    padding = 20\n",
        "    x = max(0, x - padding)\n",
        "    y = max(0, y - padding)\n",
        "    w = w + 2 * padding\n",
        "    h = h + 2 * padding\n",
        "\n",
        "    # Crop the region of interest (ROI)\n",
        "    cropped = frame[y:y + h, x:x + w]\n",
        "\n",
        "    return cropped\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "phz7D7qkw2vw"
      },
      "outputs": [],
      "source": [
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define the codec and output video format\n",
        "out = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Detect faces in the frame\n",
        "    faces = detector.detect_faces(frame,\n",
        "                                  fit_to_image=False,\n",
        "                                  limit_boundaries_landmarks=True,\n",
        "                                  min_face_size=400,  # default 20\n",
        "                                  min_size=20,  # default min size of smallest scale\n",
        "                                  scale_factor=0.709,  # default. Increase\n",
        "                                  threshold_pnet=0.6,  # default Up\n",
        "\n",
        "                                  threshold_rnet=0.85,  # default\n",
        "                                  threshold_onet=0.6,  # default\n",
        "\n",
        "                                  nms_pnet=0.7,\n",
        "                                  nps_pnet2=0.8,\n",
        "\n",
        "                                  steps_factor=0.5,  # default\n",
        "                                  # output_type='numpy'\n",
        "                                  )\n",
        "\n",
        "    if len(faces) > 0:\n",
        "        # Extract landmarks for the detected faces\n",
        "        landmarks_list = extract_landmarks(frame, faces)\n",
        "\n",
        "        for landmarks in landmarks_list:\n",
        "            # Crop the eye, nose, and brow area\n",
        "            cropped = crop_eye_brow(frame, landmarks)\n",
        "\n",
        "            # Optionally, display the cropped region\n",
        "            # cv2.imshow('Cropped Region', cropped)\n",
        "            # cv2.waitKey(1)  # Display for 1 ms\n",
        "\n",
        "    # Write frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "# Release video objects\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsFAA90Sw87X"
      },
      "outputs": [],
      "source": [
        "output_video_path = '/content/output_video.mp4'  # Local path in Colab\n",
        "drive_output_path = '/content/drive/MyDrive/Personal/BUDKA/output_video_short.mp4'  # Path in Google Drive\n",
        "\n",
        "# Move the video to Google Drive\n",
        "!cp {output_video_path} {drive_output_path}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLouYUQIy6tl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}